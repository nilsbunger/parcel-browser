from pprint import pprint
import re
import sys

from charset_normalizer.cli.normalizer import query_yes_no
from pandas import DataFrame, ExcelFile
import pandas as pd

from elt.lib.elt_utils import db_model_with_run_date, get_elt_pipe_filenames
from elt.lib.types import GisData, Juri
from dateutil.parser import parse as date_parse
from parsnip.settings import BASE_DIR

MODELS_DIR = BASE_DIR / "elt" / "models"


def sanitize(name):
    """Return a name converted to lowercase and underscored, with non-alphanumeric characters removed."""
    # # Fetch everything up to first non-alpha character, while also having tighter rules for first character.
    base = re.sub("[^A-Za-z0-9_\- ]", "_", name.strip().lower())
    # convert multiple spaces, dashes, and underscores to an underscore
    base = re.sub("[ _\-]+", "_", base)
    base = re.sub("_$", "", base)  # remove trailing underscore
    if base[0].isdigit():
        # first character is a digit - prepend an underscore
        base = "_" + base
    return base


def confirm_overwrite(fname):
    if (fname).exists():
        print(f"WARNING: {fname}' already exists...")
        if not query_yes_no("Overwrite?", default="no"):
            print("Skipping...")
            return False
    return True


def camelcase(name):
    """Return a ready-for-DB camel-cased name based on an arbitrary incoming name."""
    m = sanitize(name)
    if not m:
        raise ValueError("ERROR: Couldn't convert name to camel-case: ", name)
    base_str = m.strip()
    base_str = "".join(x.capitalize() for x in re.split("[ _]", base_str))
    # include leading underscore because it fixes values that start with a number.
    if m[0] == "_":
        base_str = "_" + base_str
    return base_str


def write_db_model_file(model_name, model_name_camel, sheet_df):
    generated_python = generate_py_for_model(model_name_camel, sheet_df)
    if confirm_overwrite(MODELS_DIR / f"{model_name}.py"):
        print("Writing to ", MODELS_DIR / f"{model_name}.py")
        with open(MODELS_DIR / f"{model_name}.py", "w") as f:
            f.write(generated_python)


pandas_field_to_db_field = {
    "object": "models.CharField(max_length=254, null=True, blank=True)",
    "int64": "models.IntegerField(null=True, blank=True)",
    "float64": "models.FloatField(null=True, blank=True)",
    "bool": "models.BooleanField(null=True, blank=True)",
}


def parse_sf_he(xls: ExcelFile, full_sheet_name: str, friendly_sheet_name: str):
    """Parse the SF HE data from excel. Called by extract_from_excel dynamically."""
    match friendly_sheet_name:
        case "table_a":
            enum_cols = ["ex_gp_des", "ex_zoning", "ex_use_vac", "infra", "public", "site_stat", "id_last2", "opt1"]
            int_cols = ["zip5"]
            skip_cols = ["jurisdict"]
            header_rows = [1]
        case "table_b":
            # fmt:off
            enum_cols = ['shortfall', 'ex_gp_type', 'ex_zoning', 'm1_gp_type', 'm2_gp_type', 'm3_gp_type',
                         'm1_zoning', 'm2_zoning', 'm3_zoning', 'vacant', 'ex_use', 'infra']
            int_cols = ["zip5"]
            skip_cols = ["jurisdict"]
            header_rows = [1]
            # fmt:on
        case "table_c":
            enum_cols = ["zoning_type"]
            int_cols = []
            skip_cols = []
            header_rows = [2]
        case _:
            print(f"Unprocessed sheet: {full_sheet_name}")
            return None
    print(f"Processing Sheet {full_sheet_name} (aka {friendly_sheet_name})...")

    df = pd.read_excel(xls, full_sheet_name, header=header_rows)
    orig_cols = list(df.columns)  # keep a copy of the original column names so we can compare
    # Sanitize column names
    df.rename(columns=lambda x: sanitize(x), inplace=True)

    cols = list(df.columns)

    cols_to_check = enum_cols + skip_cols + int_cols
    try:
        for col in cols_to_check:
            if col not in cols:
                raise ValueError(f"Error: column {col} not found in {friendly_sheet_name}")
        df.drop(columns=skip_cols, inplace=True)
        for col in enum_cols:
            df[col] = df[col].astype("category")
        for col in int_cols:
            df[col] = df[col].fillna(-1)  # get rid of NaN for conversion, by turning them to -1
            df[col] = df[col].astype("int64")
    except Exception as e:
        print(f"Error processing sheet {friendly_sheet_name}: {e}")
        raise e
    print("df:", df)
    print("df datatypes:", [(x, df[x].dtype.name) for x in df.columns])
    # Prompt.ask("Your choice? ", choices=prompt_options)
    return df


def generate_py_for_model(model_name_camel, sheet_df):
    """Create python code for a django model based on the columns in the sheet_df."""
    header_lines = [
        "# Autogenerated by extract_from_excel.py",
        "from django.contrib.gis.db import models",
        "",
        f"class {model_name_camel}(models.Model):",
    ]
    # main body lines
    lines = [f"    run_date = models.DateField()"]
    # lines for enums (need to come before usage)
    enum_lines = []
    for col in sheet_df.columns:
        dt = sheet_df[col].dtype
        if dt.name in pandas_field_to_db_field:
            lines.append(f"    {col} = {pandas_field_to_db_field[dt.name]}")
        elif dt.name == "category":
            # create text for a django class that represents the enum inside the model class
            # get the enum values from the column
            enum_name = camelcase(f"{col}_enum")
            used_cats = set({})
            lines.append(f"    {col} = models.IntegerField(choices={enum_name}.choices, null=True, blank=True)")
            enum_lines.append(f"    class {enum_name}(models.IntegerChoices):")
            cat_mappings = dict({})
            for idx, cat in enumerate(sheet_df[col].cat.categories):
                safe_cat = camelcase(cat)
                if safe_cat in ["Ncdlakesidevillage", "Neighborhoodcommercialdistrict", "Ncd24Thnoevalley"]:
                    print("FOUND IT")
                cat_mappings[safe_cat] = cat
                if safe_cat in used_cats:
                    print(f"WARNING: Skipping duplicate category: {cat}.(prev name={cat_mappings[safe_cat]}")
                else:
                    used_cats.add(safe_cat)
                    enum_lines.append(f"        {safe_cat} = {idx}")
        else:
            print(f"ERROR: Unhandled data type: {dt}")
            sys.exit(1)
    lines = header_lines + enum_lines + lines
    result = "\n".join(lines)
    return result


def extract_from_excel(geo: Juri, datatype: GisData, thru_data=None):
    """ """
    print(f"Extract from excel: geo={geo.value}, data={datatype.value}")
    pipestage_dirname = "0.excel"
    existing_files, resolved_datatype, _ = get_elt_pipe_filenames(
        geo, datatype, pipestage_dirname, extension="xlsx", expect_existing=True
    )
    latest_file = existing_files[0]
    print("Extracting from latest matching file: ", latest_file)
    date_from_filename = date_parse(latest_file.stem.split("_")[0], yearfirst=True).date()

    # load the excel file from latest_file
    xls = pd.ExcelFile(latest_file)
    # keep sheet names only up to first dash (effectively treating the dash like a comment char)
    full_sheet_names = xls.sheet_names
    for full_sheet_name in full_sheet_names:
        sanitized_sheet_name = sanitize(re.match("^[^\-]+", full_sheet_name)[0])
        parser_fn = globals()[f"parse_{geo.name}_{resolved_datatype}"]
        model_name = "raw_" + geo.name + "_" + resolved_datatype + "_" + sanitized_sheet_name
        model_name_camel = camelcase(model_name)

        # Call parser for sheet (eg: parse_sf_he)
        sheet_df: DataFrame | None = parser_fn(xls, full_sheet_name, sanitized_sheet_name)
        if sheet_df is None:
            continue  # skip unparsed sheets
        # Get DB model if it exists
        db_model = db_model_with_run_date(model_name_camel, date_from_filename)
        # if model doesn't exist, generate python for the model and write the file.
        if not db_model:
            print(f"DB model {model_name_camel} doesn't exist. Generating python code for it...")
            write_db_model_file(model_name, model_name_camel, sheet_df)
        else:
            save_df_to_db(sheet_df, db_model)

    print("Done")


def save_df_to_db(sheet_df, db_model):
    print("SAVING")
    ...
